{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add open and close sentence tags\n",
    "\n",
    "def addS(text):\n",
    "\n",
    "    for i in range(len(text)):\n",
    "        if text[i][0] != u'<s>':\n",
    "            text[i].insert(0, u'<s>')\n",
    "\n",
    "        if text[i][-1] != u'</s>':\n",
    "            text[i].append(u'</s>')\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make everything lowercase\n",
    "def lowerAll(text):\n",
    "\tfor sent in range(len(text)):\n",
    "\t\tfor word in range(len(text[sent])):\n",
    "\t\t\ttext[sent][word] = text[sent][word].lower()\n",
    "\n",
    "\treturn text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create list of ngram of length specified by user\n",
    "def createNGList(text,gramcount): #takes list of lists and integer specifying ngram\n",
    "    \n",
    "\tNGList = []\n",
    "    \n",
    "\tfor sent in text:\n",
    "        \n",
    "\t\tif gramcount==1:\n",
    "\t\t\tfor word in sent:\n",
    "\t\t\t\tNGList.append(word)\n",
    "                \n",
    "\t\telse:\n",
    "            \n",
    "\t\t\tfor word in range(gramcount, len(sent)+1):\n",
    "\t\t\t\tstart_ind = int(word-gramcount)\n",
    "\t\t\t\tngram_list = sent[start_ind:word]\n",
    "\t\t\t\tngram_tuples = tuple(ngram_list)\n",
    "\t\t\t\tNGList.append(ngram_tuples)\n",
    "\n",
    "\treturn NGList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List only n-grams that start with seed word\n",
    "# Randomize list\n",
    "# def nextWord(seed, NGs):\n",
    "#     choices = [words[1:len(words)] for words in NGs if words[0] == seed]\n",
    "#     random.shuffle(choices)\n",
    "#     return choices\n",
    "def nextWord(seed, NGdict):\n",
    "    keys = [(key[1:len(key)],NGdict[key]) for key in NGdict.keys() if key[0] == seed]\n",
    "    sorted(keys,key=lambda x:x[1])\n",
    "    \n",
    "    options = keys\n",
    "    random.shuffle(options)\n",
    "\n",
    "    return options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dePunct(text):\n",
    "    puncts = [',','.','?','!','\"',':',';']\n",
    "    for char in text:\n",
    "        if char in puncts:\n",
    "#             print \"found one!\"\n",
    "            text2 = text.replace(char, ' %s '%(char))\n",
    "\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(dic):\n",
    "\n",
    "\ttotes = float(sum(dic.values()))\n",
    "\n",
    "\tfor key in dic.keys():\n",
    "\n",
    "\t\tdic[key]=dic[key]/totes\n",
    "\n",
    "\treturn dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictify(NGList):\n",
    "    NGdict = {}\n",
    "    for NGram in NGList:\n",
    "        NGdict.setdefault(NGram, 1)\n",
    "    NGdict = normalize(NGdict)\n",
    "    \n",
    "    return NGdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('Trump_speeches.txt', 'r')\n",
    "# f = open('sampler.txt', 'r')\n",
    "data = f.read()\n",
    "data = data.decode('utf-8')\n",
    "data = dePunct(data)\n",
    "sents2 = sent_tokenize(data)\n",
    "sents2 = [sent2.split() for sent2 in sents2]\n",
    "# print sents2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text = lowerAll(sents2)\n",
    "\n",
    "# sText = addS(text)\n",
    "\n",
    "sText = addS(sents2)\n",
    "\n",
    "# print len(sText)\n",
    "# textwo = [sent for sent in sText if sent[0]==u'<s>']\n",
    "# print len(textwo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nums = [2,3]\n",
    "\n",
    "NGList = []\n",
    "NGdict = {}\n",
    "\n",
    "for num in nums:\n",
    "#     print num,\n",
    "    NG_sublist = createNGList(sText, num)\n",
    "    NG_subdict = dictify(NG_sublist)\n",
    "#     print len(NG_sublist)\n",
    "#     print NG_sublist,\"\\n\"\n",
    "    NGList.extend(NG_sublist)\n",
    "    NGdict.update(NG_subdict)\n",
    "    \n",
    "#NGList is a LIST of TUPLES for dictionary key-making purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#weight the ngrams by frequency\n",
    "# NGdict = dictify(NGList)\n",
    "# key = NGdict.keys()[0]\n",
    "# print key, NGdict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTwo weeks before I even say this . Bush is totally against Israel . And before I even genocide . And further, it would never recovered . Seven, if any, is president of speeches that is threatened by the special interests, or support, radical groups and beliefs . Now, it’s like — they’re great leader, and we need the issue anymore . It makes that deal, who’s just about all sorts of wonderful family . Some say within an international foreign policy is a talent our other oppressive regimes on competence, because Ford takes too much just the previous deal to work . All Americans . So Ford will call for a launching pad for saying far as Planned Parenthood has absolutely impossible . That’s not — a great negotiator . I’ll do it , but also intended to frighten Europe or anything .\n"
     ]
    }
   ],
   "source": [
    "sentences = 0\n",
    "print \"\\t\",\n",
    "while sentences != 12:\n",
    "    seed = u'<s>'\n",
    "#     print sentences\n",
    "\n",
    "    while seed != u'</s>':\n",
    "        \n",
    "#         choices = nextWord(seed, NGList)\n",
    "        choices = nextWord(seed, NGdict)[0]\n",
    "        for wurd in choices[0]:\n",
    "            if wurd != u'</s>':\n",
    "                print wurd,\n",
    "\n",
    "        seed = choices[0][-1]\n",
    "#         print seed,\n",
    "        \n",
    "    sentences = sentences+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
